# from langchain_google_genai import ChatGoogleGenerativeAI
# from langchain_core.messages import HumanMessage
# import os 

# os.environ["GOOGLE_API_KEY"] = "AIzaSyCUwZJzq3Tlr6sNZ5jlepSABTVXXQn1LuA"
# # Initialize the chat model (e.g., gemini-2.5-flash)
# # You can specify a different model if needed
# llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")

# # Invoke the model
# response = llm.invoke([HumanMessage(content="Explain the use of Gemini in LangChain")])
# print(response.content)
